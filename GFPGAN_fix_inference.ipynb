{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RJtKN6ANUADM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nick088Official/GFPGAN-Fix/blob/master/GFPGAN_fix_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtKN6ANUADM"
      },
      "source": [
        "# GFPGAN Inference Demo  (Restore faces of images/videos)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n",
        "[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n",
        "\n",
        "## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
        "\n",
        "GFPGAN is a blind face restoration algorithm towards real-world face images. <br>\n",
        "It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n",
        "\n",
        "**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n",
        "\n",
        "###Enjoy! :-)\n",
        "\n",
        "<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ",
        "cellView": "form",
        "outputId": "94d9fb68-516c-47eb-9400-0d564a2093ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Installation\n",
        "#@markdown Before start, make sure that you choose\n",
        "#@markdown * Runtime Type = Python 3\n",
        "#@markdown * Hardware Accelerator = GPU\n",
        "\n",
        "#@markdown in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "#@markdown By running this, we clone the repository, set up the envrironment, and download the pre-trained model which we use 1.2 , 1.3 , 1.4 , RestoreFormer , CodeFormer.\n",
        "\n",
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN-Fix\n",
        "!git clone https://github.com/Nick088Official/GFPGAN-Fix.git\n",
        "%cd GFPGAN-Fix\n",
        "\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Set up the environment\n",
        "# We install and use new-BasicSR for both training and inference\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "!pip uninstall -y basicsr # have to uninstall it as it gives error to GFPGAN but still gets installed from other package\n",
        "!pip install -r requirements.txt # which installs other packages such as new-basicsr\n",
        "\n",
        "if device == \"cuda\":\n",
        "  !BASICSR_EXT=True pip install new-basicsr # for installing cuda extensions for v1 model for colorization\n",
        "\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/CodeFormer.pth -P experiments/pretrained_models\n",
        "clear_output()\n",
        "print(\"Installed GFPGAN, its requirements and the models.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed GFPGAN, its requirements and the models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHc73Up70ZA"
      },
      "source": [
        "## Inference Images\n",
        "Usage: `python inference_gfpgan.py -i inputs/upload -o results [options]...`\n",
        "\n",
        "Options:\n",
        "```\n",
        "  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3 | 1.4. | RestoreFormer\n",
        "  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "  -suffix              Suffix of the restored faces\n",
        "  -only_center_face    Only restore the center face\n",
        "  -aligned             Input are aligned faces\n",
        "  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdMZYp0T7NAy",
        "cellView": "form"
      },
      "source": [
        "#@title Upload Input Image\n",
        "\n",
        "upload_folder = 'inputs/upload'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "# upload input\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  print(f'moved {filename} to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQVC3s97z4z",
        "cellView": "form"
      },
      "source": [
        "#@title Inference\n",
        "\n",
        "!rm -rf results\n",
        "\n",
        "options = \"-v 1.3 -s 2 --bg_upsampler realesrgan\" #@param {type:\"string\"}\n",
        "\n",
        "!python inference_gfpgan.py -i inputs/upload -o results {options}\n",
        "\n",
        "!ls results/cmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIeL_NJO8A3B",
        "cellView": "form"
      },
      "source": [
        "#@title Visualize Input vs Output Faces\n",
        "# We first visualize the cropped faces\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'results/cropped_faces'\n",
        "result_folder = 'results/restored_faces'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_2ylqP9qXY",
        "cellView": "form"
      },
      "source": [
        "#@title View the whole Input vs Output Image\n",
        "# We then visualize the whole image\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/upload'\n",
        "result_folder = 'results/restored_imgs'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuBCgeH08tdn",
        "cellView": "form"
      },
      "source": [
        "#@title Download results\n",
        "#@markdown It will download you a .zip, unzip it however you want\n",
        "#@markdown - The 'cmp' folder contains a comparison between the Input vs Output faces,\n",
        "#@markdown - The 'cropped_faces' folder contains only the cropped Input Face\n",
        "#@markdown - The 'restored_faces' folder contains only the Output Face (Restored one)\n",
        "#@markdown - The 'restored_imgs' folder contains the whole Output Image restored with also the Background\n",
        "\n",
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system('zip -r download.zip results')\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Videos\n",
        "Usage: `python inference_gfpgan.py -i inputs/upload -o results [options]...`\n",
        "\n",
        "Options:\n",
        "```\n",
        "  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3 | 1.4. | RestoreFormer\n",
        "  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "  -suffix              Suffix of the restored faces\n",
        "  -only_center_face    Only restore the center face\n",
        "  -aligned             Input are aligned faces\n",
        "  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "```"
      ],
      "metadata": {
        "id": "HQBkHtmJn8_0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1tiyMZJW5td",
        "cellView": "form"
      },
      "source": [
        "#@title Upload Input Video\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "video_folder = 'videos'\n",
        "video_result_folder = 'results_videos'\n",
        "video_mp4_result_folder = 'results_mp4_videos'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "  print(upload_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "if os.path.isdir(video_folder):\n",
        "  print(video_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_folder)\n",
        "\n",
        "if os.path.isdir(video_result_folder):\n",
        "  print(video_result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_result_folder)\n",
        "\n",
        "if os.path.isdir(video_mp4_result_folder):\n",
        "  print(video_mp4_result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_mp4_result_folder)\n",
        "\n",
        "if os.path.isdir(result_folder):\n",
        "  print(result_folder+\" exists\")\n",
        "\n",
        "else :\n",
        "  os.mkdir(result_folder)\n",
        "\n",
        "\n",
        "upload_folder = 'videos'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "# upload input\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  print(f'moved {filename} of {fps} fps to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import isfile, join\n",
        "import subprocess\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# assign directory\n",
        "directory = 'videos' #PATH_WITH_INPUT_VIDEOS\n",
        "zee = 0\n",
        "\n",
        "#deletes frames from previous video\n",
        "for f in os.listdir(upload_folder):\n",
        "    os.remove(os.path.join(upload_folder, f))\n",
        "\n",
        "#clearing previous .avi files\n",
        "for f in os.listdir(video_result_folder):\n",
        "    os.remove(os.path.join(video_result_folder, f))\n",
        "\n",
        "#clearing .mp4 result files\n",
        "for f in os.listdir(video_mp4_result_folder):\n",
        "    os.remove(os.path.join(video_mp4_result_folder, f))\n",
        "\n",
        "\n",
        "def convert_frames_to_video(pathIn,pathOut,fps):\n",
        "    frame_array = []\n",
        "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "    #for sorting the file names properly\n",
        "    files.sort(key = lambda x: int(x[5:-4]))\n",
        "    size2 = (0,0)\n",
        "\n",
        "    for i in range(len(files)):\n",
        "        filename=pathIn + files[i]\n",
        "        #reading each files\n",
        "        img = cv2.imread(filename)\n",
        "        height, width, layers = img.shape\n",
        "        size = (width,height)\n",
        "        size2 = size\n",
        "        print(filename)\n",
        "        #inserting the frames into an image array\n",
        "        frame_array.append(img)\n",
        "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size2)\n",
        "    for i in range(len(frame_array)):\n",
        "        # writing to a image array\n",
        "        out.write(frame_array[i])\n",
        "    out.release()\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "\n",
        "\n",
        "      print(\"PROCESSING :\"+str(f)+\"\\n\")\n",
        "      # Read the video from specified path\n",
        "\n",
        "      #video to frames\n",
        "      cam = cv2.VideoCapture(str(f))\n",
        "\n",
        "      try:\n",
        "\n",
        "          # PATH TO STORE VIDEO FRAMES\n",
        "          if not os.path.exists('upload'):\n",
        "              os.makedirs('upload')\n",
        "\n",
        "      # if not created then raise error\n",
        "      except OSError:\n",
        "          print ('Error: Creating directory of data')\n",
        "\n",
        "      # frame\n",
        "      currentframe = 0\n",
        "\n",
        "\n",
        "      while(True):\n",
        "\n",
        "          # reading from frame\n",
        "          ret,frame = cam.read()\n",
        "\n",
        "          if ret:\n",
        "              # if video is still left continue creating images\n",
        "              name = 'upload/frame' + str(currentframe) + '.jpg'\n",
        "\n",
        "              # writing the extracted images\n",
        "              cv2.imwrite(name, frame)\n",
        "\n",
        "\n",
        "                # increasing counter so that it will\n",
        "                # show how many frames are created\n",
        "              currentframe += 1\n",
        "              print(currentframe)\n",
        "          else:\n",
        "              #deletes all the videos you uploaded for upscaling\n",
        "              #for f in os.listdir(video_folder):\n",
        "              #  os.remove(os.path.join(video_folder, f))\n",
        "\n",
        "              break\n",
        "\n",
        "        # Release all space and windows once done\n",
        "      cam.release()\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "      #apply super-resolution on all frames of a video\n",
        "      #scale factor is by 3.5x\n",
        "\n",
        "      #in the line below '2' stands for upscaling by factor of 2\n",
        "      options = \"-v 1.3 -s 2 --bg_upsampler realesrgan\" #@param {type:\"string\"}\n",
        "\n",
        "      !python inference_gfpgan.py -i upload -o results {options}\n",
        "\n",
        "      #after upscaling just delete the source frames\n",
        "      for f in os.listdir(upload_folder):\n",
        "          os.remove(os.path.join(upload_folder, f))\n",
        "\n",
        "\n",
        "      #convert super res frames to .avi\n",
        "      pathIn = 'results/restored_imgs/'\n",
        "\n",
        "      zee = zee+1\n",
        "      fName = \"video\"+str(zee)\n",
        "      filenameVid = f\"{fName}.avi\"\n",
        "\n",
        "      pathOut = \"results_videos/\"+filenameVid\n",
        "\n",
        "      fps = 25.0 #change this to FPS of your source video\n",
        "\n",
        "      convert_frames_to_video(pathIn, pathOut, fps)\n",
        "\n",
        "      #after processing frames converted to .avi video , delete upscaled frames from previous video\n",
        "      for f in os.listdir('results/restored_imgs'):\n",
        "          os.remove(os.path.join('results/restored_imgs', f))\n",
        "\n",
        "      #convert .avi to .mp4\n",
        "      src = 'results_videos/'\n",
        "      dst = 'results_mp4_videos/'\n",
        "\n",
        "      for root, dirs, filenames in os.walk(src, topdown=False):\n",
        "          #print(filenames)\n",
        "          for filename in filenames:\n",
        "              print('[INFO] 1',filename)\n",
        "              try:\n",
        "                  _format = ''\n",
        "                  if \".flv\" in filename.lower():\n",
        "                      _format=\".flv\"\n",
        "                  if \".mp4\" in filename.lower():\n",
        "                      _format=\".mp4\"\n",
        "                  if \".avi\" in filename.lower():\n",
        "                      _format=\".avi\"\n",
        "                  if \".mov\" in filename.lower():\n",
        "                      _format=\".mov\"\n",
        "\n",
        "                  inputfile = os.path.join(root, filename)\n",
        "                  print('[INFO] 1',inputfile)\n",
        "                  outputfile = os.path.join(dst, filename.lower().replace(_format, \".mp4\"))\n",
        "                  subprocess.call(['ffmpeg', '-i', inputfile, outputfile])\n",
        "              except:\n",
        "                  print(\"An exception occurred\")\n",
        "\n",
        "      clear_output(wait=True)\n",
        "\n",
        "      #clearing previous .avi files\n",
        "      for f in os.listdir(video_result_folder):\n",
        "          os.remove(os.path.join(video_result_folder, f))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VE8gV51NoZ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display Input vs Output Video\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load input and output videos\n",
        "input_video = cv2.VideoCapture(\"/content/GFPGAN-Fix/upload/\")\n",
        "output_video = cv2.VideoCapture(\"/content/GFPGAN-Fix/results_mp4_videos/\")\n",
        "\n",
        "# Get video dimensions\n",
        "input_width, input_height = int(input_video.get(3)), int(input_video.get(4))\n",
        "output_width, output_height = int(output_video.get(3)), int(output_video.get(4))\n",
        "\n",
        "# Create a blank canvas to display both videos side by side\n",
        "canvas_width = input_width + output_width\n",
        "canvas_height = max(input_height, output_height)\n",
        "canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
        "\n",
        "# Read frames from input and output videos\n",
        "while True:\n",
        "    input_frame_exists, input_frame = input_video.read()\n",
        "    output_frame_exists, output_frame = output_video.read()\n",
        "\n",
        "    if not input_frame_exists or not output_frame_exists:\n",
        "        break\n",
        "\n",
        "    # Resize frames to fit the canvas\n",
        "    input_frame = cv2.resize(input_frame, (input_width, input_height))\n",
        "    output_frame = cv2.resize(output_frame, (output_width, output_height))\n",
        "\n",
        "    # Place input frame on the left and output frame on the right\n",
        "    canvas[:, :input_width] = input_frame\n",
        "    canvas[:, input_width:] = output_frame\n",
        "\n",
        "    # Display the canvas\n",
        "    cv2.imshow(\"Input and Output Videos\", canvas)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and close the window\n",
        "input_video.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r-d7ih6oql1O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}