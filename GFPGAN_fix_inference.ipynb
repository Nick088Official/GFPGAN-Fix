{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RJtKN6ANUADM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nick088Official/GFPGAN-Fix/blob/master/GFPGAN_fix_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtKN6ANUADM"
      },
      "source": [
        "# GFPGAN Inference Demo  (Restore faces of images)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n",
        "[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n",
        "\n",
        "## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
        "\n",
        "GFPGAN is a blind face restoration algorithm towards real-world face images. <br>\n",
        "It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n",
        "\n",
        "**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n",
        "\n",
        "###Enjoy! :-)\n",
        "\n",
        "<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ",
        "cellView": "form"
      },
      "source": [
        "#@title Installation\n",
        "#@markdown Before start, make sure that you choose\n",
        "#@markdown * Runtime Type = Python 3\n",
        "#@markdown * Hardware Accelerator = GPU\n",
        "\n",
        "#@markdown in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "#@markdown By running this, we clone the repository, set up the envrironment, and download the pre-trained model which we use 1.2 , 1.3 , 1.4 , RestoreFormer , CodeFormer.\n",
        "\n",
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN-Fix\n",
        "!git clone https://github.com/Nick088Official/GFPGAN-Fix.git\n",
        "%cd GFPGAN-Fix\n",
        "\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Set up the environment\n",
        "# We install and use new-BasicSR for both training and inference\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "!pip uninstall -y basicsr # have to uninstall it as it gives error to GFPGAN but still gets installed from other package\n",
        "!pip install -r requirements.txt # which installs other packages such as new-basicsr\n",
        "\n",
        "if device == \"cuda\":\n",
        "  !BASICSR_EXT=True pip install new-basicsr # for installing cuda extensions for v1 model for colorization\n",
        "\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/CodeFormer.pth -P experiments/pretrained_models\n",
        "clear_output()\n",
        "print(\"Installed GFPGAN, it's requirements and the models.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdMZYp0T7NAy",
        "cellView": "form"
      },
      "source": [
        "#@title Upload Input Image/Video\n",
        "\n",
        "input_type = \"video\" #@param ['image', 'video']\n",
        "\n",
        "if input_type == \"image\":\n",
        "  upload_folder = 'inputs/upload'\n",
        "else:\n",
        "  upload_folder = 'videos'\n",
        "  import subprocess\n",
        "  cap = cv2.VideoCapture(upload_folder)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  cap.release()\n",
        "\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "# upload input\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  if input_type == \"image\":\n",
        "    print(f'moved {filename} to {dst_path}')\n",
        "  else:\n",
        "    print(f'moved {filename} of {fps} fps to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHc73Up70ZA"
      },
      "source": [
        "## 3. Inference\n",
        "Usage: `python inference_gfpgan.py -i inputs/whole_imgs -o results [options]...`\n",
        "\n",
        "Options:\n",
        "```\n",
        "  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3 | 1.4. | RestoreFormer\n",
        "  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "  -suffix              Suffix of the restored faces\n",
        "  -only_center_face    Only restore the center face\n",
        "  -aligned             Input are aligned faces\n",
        "  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQVC3s97z4z",
        "cellView": "form"
      },
      "source": [
        "#@title Inference\n",
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo\n",
        "\n",
        "if input_type == \"video\":\n",
        "  # assign directory\n",
        "  directory = 'videos' #PATH_WITH_INPUT_VIDEOS\n",
        "  zee = 0\n",
        "  def convert_frames_to_video(pathIn,pathOut,fps):\n",
        "    frame_array = []\n",
        "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "    #for sorting the file names properly\n",
        "    files.sort(key = lambda x: int(x[5:-4]))\n",
        "    size2 = (0,0)\n",
        "\n",
        "    for i in range(len(files)):\n",
        "        filename=pathIn + files[i]\n",
        "        #reading each files\n",
        "        img = cv2.imread(filename)\n",
        "        height, width, layers = img.shape\n",
        "        size = (width,height)\n",
        "        size2 = size\n",
        "        print(filename)\n",
        "        #inserting the frames into an image array\n",
        "        frame_array.append(img)\n",
        "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size2)\n",
        "    for i in range(len(frame_array)):\n",
        "        # writing to a image array\n",
        "        out.write(frame_array[i])\n",
        "    out.release()\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "\n",
        "\n",
        "      print(\"PROCESSING :\"+str(f)+\"\\n\")\n",
        "      # Read the video from specified path\n",
        "\n",
        "      #video to frames\n",
        "      cam = cv2.VideoCapture(str(f))\n",
        "\n",
        "      try:\n",
        "\n",
        "          # PATH TO STORE VIDEO FRAMES\n",
        "          if not os.path.exists('upload'):\n",
        "              os.makedirs('upload')\n",
        "\n",
        "      # if not created then raise error\n",
        "      except OSError:\n",
        "          print ('Error: Creating directory of data')\n",
        "\n",
        "      # frame\n",
        "      currentframe = 0\n",
        "\n",
        "      #clear all folders\n",
        "\n",
        "\n",
        "      #deletes upscaled frames from previous video\n",
        "      #for f in os.listdir(result_folder):\n",
        "      #  os.remove(os.path.join(result_folder, f))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      while(True):\n",
        "\n",
        "          # reading from frame\n",
        "          ret,frame = cam.read()\n",
        "\n",
        "          if ret:\n",
        "              # if video is still left continue creating images\n",
        "              name = 'upload/frame' + str(currentframe) + '.jpg'\n",
        "\n",
        "              # writing the extracted images\n",
        "              cv2.imwrite(name, frame)\n",
        "\n",
        "\n",
        "                # increasing counter so that it will\n",
        "                # show how many frames are created\n",
        "              currentframe += 1\n",
        "              print(currentframe)\n",
        "          else:\n",
        "              #deletes all the videos you uploaded for upscaling\n",
        "              #for f in os.listdir(video_folder):\n",
        "              #  os.remove(os.path.join(video_folder, f))\n",
        "\n",
        "              break\n",
        "\n",
        "        # Release all space and windows once done\n",
        "      cam.release()\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "      #apply super-resolution on all frames of a video\n",
        "      #scale factor is by 3.5x\n",
        "\n",
        "!rm -rf results\n",
        "\n",
        "options = \"-v 1.3 -s 2 --bg_upsampler realesrgan\" #@param {type:\"string\"}\n",
        "\n",
        "!python inference_gfpgan.py -i inputs/upload -o results {options}\n",
        "\n",
        "if input_type == \"video\":\n",
        "  #convert super res frames to .avi\n",
        "  pathIn = 'results/restored_imgs/'\n",
        "\n",
        "  zee = zee+1\n",
        "  fName = \"video\"+str(zee)\n",
        "  filenameVid = f\"{fName}.avi\"\n",
        "\n",
        "  pathOut = \"results_videos/\"+filenameVid\n",
        "\n",
        "\n",
        "  convert_frames_to_video(pathIn, pathOut, fps)\n",
        "\n",
        "  #after processing frames converted to .avi video , delete upscaled frames from previous video\n",
        "  for f in os.listdir('results/restored_imgs'):\n",
        "      os.remove(os.path.join('results/restored_imgs', f))\n",
        "\n",
        "  #convert .avi to .mp4\n",
        "  src = 'results_videos/'\n",
        "  dst = 'results_mp4_videos/'\n",
        "\n",
        "  for root, dirs, filenames in os.walk(src, topdown=False):\n",
        "      #print(filenames)\n",
        "      for filename in filenames:\n",
        "          print('[INFO] 1',filename)\n",
        "          try:\n",
        "              _format = ''\n",
        "              if \".flv\" in filename.lower():\n",
        "                  _format=\".flv\"\n",
        "              if \".mp4\" in filename.lower():\n",
        "                  _format=\".mp4\"\n",
        "              if \".avi\" in filename.lower():\n",
        "                  _format=\".avi\"\n",
        "              if \".mov\" in filename.lower():\n",
        "                  _format=\".mov\"\n",
        "\n",
        "              inputfile = os.path.join(root, filename)\n",
        "              print('[INFO] 1',inputfile)\n",
        "              outputfile = os.path.join(dst, filename.lower().replace(_format, \".mp4\"))\n",
        "              subprocess.call(['ffmpeg', '-i', inputfile, outputfile])\n",
        "          except:\n",
        "              print(\"An exception occurred\")\n",
        "\n",
        "!ls results/cmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuBCgeH08tdn",
        "cellView": "form"
      },
      "source": [
        "#@title Download results\n",
        "#@markdown It will download you a .zip, unzip it however you want\n",
        "#@markdown - The 'cmp' folder contains a comparison between the Input vs Output faces,\n",
        "#@markdown - The 'cropped_faces' folder contains only the cropped Input Face\n",
        "#@markdown - The 'restored_faces' folder contains only the Output Face (Restored one)\n",
        "#@markdown - The 'restored_imgs' folder contains the whole Output Image restored with also the Background\n",
        "\n",
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system('zip -r download.zip results')\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}