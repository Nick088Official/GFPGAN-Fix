{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RJtKN6ANUADM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nick088Official/GFPGAN-Fix/blob/master/GFPGAN_fix_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtKN6ANUADM"
      },
      "source": [
        "# GFPGAN Inference Demo  (Restore faces of images/videos)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n",
        "[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n",
        "\n",
        "## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
        "\n",
        "**GFPGAN** is a blind **face restoration** algorithm towards real-world face images. <br>\n",
        "It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n",
        "\n",
        "**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n",
        "\n",
        "**Credits**: [Nick088](https://linktr.ee/Nick088), Geeve George, TencentARC\n",
        "\n",
        "###Enjoy! :-)\n",
        "\n",
        "<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH2ifWEYEfJ",
        "cellView": "form"
      },
      "source": [
        "#@title Installation\n",
        "#@markdown Before start, make sure that you choose\n",
        "#@markdown * Runtime Type = Python 3\n",
        "#@markdown * Hardware Accelerator = CPU (Slower, can't use v1 model, works fine for other ones tho) or GPU (Faster, free daily limit of around 12 hours of gpu in colab, Needed for V1 Model that use colorization)\n",
        "\n",
        "#@markdown in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "#@markdown By running this, we clone the repository, set up the envrironment, and download the pre-trained model which we use 1.2 , 1.3 , 1.4 , RestoreFormer , CodeFormer.\n",
        "\n",
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN-Fix\n",
        "!git clone https://github.com/Nick088Official/GFPGAN-Fix.git\n",
        "%cd GFPGAN-Fix\n",
        "\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU, you won't be able to use v1 model\")\n",
        "\n",
        "# Set up the environment\n",
        "# We install and use new-BasicSR for both training and inference\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "!pip uninstall -y basicsr # have to uninstall it as it gives error to GFPGAN but still gets installed from other package\n",
        "!pip install -r requirements.txt # which installs other packages such as new-basicsr\n",
        "\n",
        "if device == \"cuda\":\n",
        "  !BASICSR_EXT=True pip install new-basicsr # for installing cuda extensions for v1 model for colorization\n",
        "\n",
        "# Download the pre-trained model\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/RestoreFormer.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/CodeFormer.pth -P experiments/pretrained_models\n",
        "clear_output()\n",
        "print(\"Installed GFPGAN, its requirements and the models.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHc73Up70ZA"
      },
      "source": [
        "# Inference Images\n",
        "Usage: `python inference_gfpgan.py -i inputs/upload -o results [options]...`\n",
        "\n",
        "Options:\n",
        "```\n",
        "  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3 | 1.4. | RestoreFormer\n",
        "  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "  -suffix              Suffix of the restored faces\n",
        "  -only_center_face    Only restore the center face\n",
        "  -aligned             Input are aligned faces\n",
        "  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdMZYp0T7NAy",
        "cellView": "form"
      },
      "source": [
        "#@title Upload Input Image\n",
        "\n",
        "upload_folder = 'inputs/upload'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "# upload input\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  print(f'moved {filename} to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQVC3s97z4z",
        "cellView": "form"
      },
      "source": [
        "#@title Inference\n",
        "\n",
        "!rm -rf results\n",
        "\n",
        "options = \"-v 1.3 -s 2 --bg_upsampler realesrgan\" #@param {type:\"string\"}\n",
        "\n",
        "!python inference_gfpgan.py -i inputs/upload -o results {options}\n",
        "\n",
        "!ls results/cmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIeL_NJO8A3B",
        "cellView": "form"
      },
      "source": [
        "#@title Visualize Input vs Output Faces\n",
        "# We first visualize the cropped faces\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'results/cropped_faces'\n",
        "result_folder = 'results/restored_faces'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_2ylqP9qXY",
        "cellView": "form"
      },
      "source": [
        "#@title View the whole Input vs Output Image\n",
        "# We then visualize the whole image\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/upload'\n",
        "result_folder = 'results/restored_imgs'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuBCgeH08tdn",
        "cellView": "form"
      },
      "source": [
        "#@title Download results\n",
        "#@markdown It will download you a .zip, unzip it however you want\n",
        "#@markdown - The 'cmp' folder contains a comparison between the Input vs Output faces,\n",
        "#@markdown - The 'cropped_faces' folder contains only the cropped Input Face\n",
        "#@markdown - The 'restored_faces' folder contains only the Output Face (Restored one)\n",
        "#@markdown - The 'restored_imgs' folder contains the whole Output Image restored with also the Background\n",
        "\n",
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system('zip -r download.zip results')\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Videos\n",
        "Usage: `python inference_gfpgan.py -i inputs/upload -o results [options]...`\n",
        "\n",
        "Options:\n",
        "```\n",
        "  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3 | 1.4. | RestoreFormer\n",
        "  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "  -suffix              Suffix of the restored faces\n",
        "  -only_center_face    Only restore the center face\n",
        "  -aligned             Input are aligned faces\n",
        "  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "```"
      ],
      "metadata": {
        "id": "HQBkHtmJn8_0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1tiyMZJW5td",
        "cellView": "form"
      },
      "source": [
        "#@title Upload Input Video\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "video_folder = 'videos'\n",
        "video_result_folder = 'results_videos'\n",
        "video_mp4_result_folder = 'results_mp4_videos'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "  print(upload_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "if os.path.isdir(video_folder):\n",
        "  print(video_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_folder)\n",
        "\n",
        "if os.path.isdir(video_result_folder):\n",
        "  print(video_result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_result_folder)\n",
        "\n",
        "if os.path.isdir(video_mp4_result_folder):\n",
        "  print(video_mp4_result_folder+\" exists\")\n",
        "else :\n",
        "  os.mkdir(video_mp4_result_folder)\n",
        "\n",
        "if os.path.isdir(result_folder):\n",
        "  print(result_folder+\" exists\")\n",
        "\n",
        "else :\n",
        "  os.mkdir(result_folder)\n",
        "\n",
        "\n",
        "\n",
        "if os.path.isdir(video_folder):\n",
        "    shutil.rmtree(video_folder)\n",
        "os.mkdir(video_folder)\n",
        "\n",
        "# upload images\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(video_folder, filename)\n",
        "  print(f'move {filename} to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from os.path import isfile, join\n",
        "import subprocess\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# assign directory\n",
        "directory = '/content/GFPGAN-Fix/videos' #PATH_WITH_INPUT_VIDEOS\n",
        "zee = 0\n",
        "\n",
        "#deletes frames from previous video\n",
        "for f in os.listdir(upload_folder):\n",
        "    os.remove(os.path.join(upload_folder, f))\n",
        "\n",
        "#deletes upscaled frames from previous video\n",
        "#for f in os.listdir('results/restored_imgs'):\n",
        "#    os.remove(os.path.join('results/restored_imgs', f))\n",
        "\n",
        "#clearing previous .avi files\n",
        "for f in os.listdir(video_result_folder):\n",
        "    os.remove(os.path.join(video_result_folder, f))\n",
        "\n",
        "#clearing .mp4 result files\n",
        "for f in os.listdir(video_mp4_result_folder):\n",
        "    os.remove(os.path.join(video_mp4_result_folder, f))\n",
        "\n",
        "\n",
        "def convert_frames_to_video(pathIn,pathOut,fps):\n",
        "    frame_array = []\n",
        "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "    #for sorting the file names properly\n",
        "    files.sort(key = lambda x: int(x[5:-4]))\n",
        "    size2 = (0,0)\n",
        "\n",
        "    for i in range(len(files)):\n",
        "        filename=pathIn + files[i]\n",
        "        #reading each files\n",
        "        img = cv2.imread(filename)\n",
        "        height, width, layers = img.shape\n",
        "        size = (width,height)\n",
        "        size2 = size\n",
        "        print(filename)\n",
        "        #inserting the frames into an image array\n",
        "        frame_array.append(img)\n",
        "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size2)\n",
        "    for i in range(len(frame_array)):\n",
        "        # writing to a image array\n",
        "        out.write(frame_array[i])\n",
        "    out.release()\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "\n",
        "\n",
        "      print(\"PROCESSING :\"+str(f)+\"\\n\")\n",
        "      # Read the video from specified path\n",
        "\n",
        "      #video to frames\n",
        "      cam = cv2.VideoCapture(str(f))\n",
        "\n",
        "      try:\n",
        "\n",
        "          # PATH TO STORE VIDEO FRAMES\n",
        "          if not os.path.exists('/content/GFPGAN-Fix/upload'):\n",
        "              os.makedirs('/content/GFPGAN-Fix/upload')\n",
        "\n",
        "      # if not created then raise error\n",
        "      except OSError:\n",
        "          print ('Error: Creating directory of data')\n",
        "\n",
        "      # frame\n",
        "      currentframe = 0\n",
        "\n",
        "      #clear all folders\n",
        "\n",
        "\n",
        "      #deletes upscaled frames from previous video\n",
        "      #for f in os.listdir(result_folder):\n",
        "      #  os.remove(os.path.join(result_folder, f))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      while(True):\n",
        "\n",
        "          # reading from frame\n",
        "          ret,frame = cam.read()\n",
        "\n",
        "          if ret:\n",
        "              # if video is still left continue creating images\n",
        "              name = '/content/GFPGAN-Fix/upload/frame' + str(currentframe) + '.jpg'\n",
        "\n",
        "              # writing the extracted images\n",
        "              cv2.imwrite(name, frame)\n",
        "\n",
        "\n",
        "                # increasing counter so that it will\n",
        "                # show how many frames are created\n",
        "              currentframe += 1\n",
        "              print(currentframe)\n",
        "          else:\n",
        "              #deletes all the videos you uploaded for upscaling\n",
        "              #for f in os.listdir(video_folder):\n",
        "              #  os.remove(os.path.join(video_folder, f))\n",
        "\n",
        "              break\n",
        "\n",
        "        # Release all space and windows once done\n",
        "      cam.release()\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "      #apply super-resolution on all frames of a video\n",
        "      #scale factor is by 3.5x\n",
        "\n",
        "      options = \"-v 1.3 -s 2 --bg_upsampler realesrgan\" #@param {type:\"string\"}\n",
        "\n",
        "      !python inference_gfpgan.py -i upload -o results {options}\n",
        "\n",
        "      #after upscaling just delete the source frames\n",
        "      for f in os.listdir(upload_folder):\n",
        "          os.remove(os.path.join(upload_folder, f))\n",
        "\n",
        "      '''\n",
        "      #rename all frames in \"results\" to remove the 'out' substring from the processing results\n",
        "      paths = (os.path.join(root, filename)\n",
        "              for root, _, filenames in os.walk('/content/GFPGAN-Fix/results')\n",
        "              for filename in filenames)\n",
        "      for path in paths:\n",
        "          newname = path.replace('_out', '')\n",
        "          if newname != path:\n",
        "              os.rename(path, newname)\n",
        "      '''\n",
        "\n",
        "      #convert super res frames to .avi\n",
        "      pathIn = '/content/GFPGAN-Fix/results/restored_imgs/'\n",
        "\n",
        "      zee = zee+1\n",
        "      fName = \"video\"+str(zee)\n",
        "      filenameVid = f\"{fName}.avi\"\n",
        "\n",
        "      pathOut = \"/content/GFPGAN-Fix/results_videos/\"+filenameVid\n",
        "\n",
        "      fps = 25.0 #change this to FPS of your source video\n",
        "\n",
        "      convert_frames_to_video(pathIn, pathOut, fps)\n",
        "\n",
        "      #after processing frames converted to .avi video , delete upscaled frames from previous video\n",
        "      for f in os.listdir('results/restored_imgs'):\n",
        "          os.remove(os.path.join('results/restored_imgs', f))\n",
        "\n",
        "      #convert .avi to .mp4\n",
        "      src = '/content/GFPGAN-Fix/results_videos/'\n",
        "      dst = '/content/GFPGAN-Fix/results_mp4_videos/'\n",
        "\n",
        "      for root, dirs, filenames in os.walk(src, topdown=False):\n",
        "          #print(filenames)\n",
        "          for filename in filenames:\n",
        "              print('[INFO] 1',filename)\n",
        "              try:\n",
        "                  _format = ''\n",
        "                  if \".flv\" in filename.lower():\n",
        "                      _format=\".flv\"\n",
        "                  if \".mp4\" in filename.lower():\n",
        "                      _format=\".mp4\"\n",
        "                  if \".avi\" in filename.lower():\n",
        "                      _format=\".avi\"\n",
        "                  if \".mov\" in filename.lower():\n",
        "                      _format=\".mov\"\n",
        "\n",
        "                  inputfile = os.path.join(root, filename)\n",
        "                  print('[INFO] 1',inputfile)\n",
        "                  outputfile = os.path.join(dst, filename.lower().replace(_format, \".mp4\"))\n",
        "                  subprocess.call(['ffmpeg', '-i', inputfile, outputfile])\n",
        "              except:\n",
        "                  print(\"An exception occurred\")\n",
        "\n",
        "      clear_output(wait=True)\n",
        "\n",
        "      #clearing previous .avi files\n",
        "      for f in os.listdir(video_result_folder):\n",
        "          os.remove(os.path.join(video_result_folder, f))\n",
        "\n",
        "      #deletes frames from previous video\n",
        "      #for f in os.listdir(upload_folder):\n",
        "      #  os.remove(os.path.join(upload_folder, f))\n",
        "\n",
        "\n",
        "\n",
        "      # if it is out of memory, try to use the `--tile` option\n",
        "# We upsample the image with the scale factor X3.5\n",
        "\n",
        "# Arguments\n",
        "# -n, --model_name: Model names\n",
        "# -i, --input: input folder or image\n",
        "# --outscale: Output scale, can be arbitrary scale factore."
      ],
      "metadata": {
        "cellView": "form",
        "id": "VE8gV51NoZ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bp1CLOX-ICT0"
      },
      "source": [
        "#@title Download results\n",
        "#@markdown It will download you a .zip, unzip it however you want\n",
        "\n",
        "#@markdown It will have 2 folders:\n",
        "\n",
        "#@markdown 1. 'results' = the results of the frames of the video\n",
        "#@markdown - The 'cmp' folder contains a comparison between the Input vs Output faces,\n",
        "#@markdown - The 'cropped_faces' folder contains only the cropped Input Face\n",
        "#@markdown - The 'restored_faces' folder contains only the Output Face (Restored one)\n",
        "#@markdown - The 'restored_imgs' folder contains the whole Output Image restored with also the Background\n",
        "\n",
        "#@markdown 2. 'results_mp4_videos' = the results of the video after the face has been restored (so basically all the frames together)\n",
        "\n",
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system('zip -r download.zip results results_mp4_videos')\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}